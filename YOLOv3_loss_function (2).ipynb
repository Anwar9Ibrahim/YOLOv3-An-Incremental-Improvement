{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkb4bj70VxDa"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from intersection_over_union import intersection_over_union"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Yolov3Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # we have different loss functions each one to calculate the loss for \n",
        "    # a specific element.\n",
        "    self.mse= nn.MSELoss() #for the box predictions.\n",
        "    self.bce= nn.BCEWithLogitsLoss() # this applies both binary cross entropy and sigmoid\n",
        "    self.entropy = nn.CrossEntropyLoss() #we used cross entropy because we have one label per box.\n",
        "    self.sigmoid= nn.Sigmoid()\n",
        "\n",
        "    # we want to wight each element of the loss function \n",
        "    # so we defined several constant numbers to mulipuly different \n",
        "    #elements of the loss function with them.\n",
        "    ##those values are NOT from the original paper###\n",
        "    self.lambda_class = 1\n",
        "    self.lambda_noobj = 10\n",
        "    self.lambda_obj = 1\n",
        "    self.lambda_box = 10\n",
        "\n",
        "  def forward(self, predictions, target, anchors):\n",
        "    #we will compute the loss for a single scale\n",
        "    #so for every forward pass we will call this three times.\n",
        "\n",
        "    #check where is the object and the noobject in the target, to make sure that we are \n",
        "    #only taking values equal to 0 or 1.\n",
        "    ## because we ignored values when IOU is greater than 0.5\n",
        "    obj= target[...,0] == 1 #binary value\n",
        "    noobj= target[...,0]==0\n",
        "\n",
        "    ####################\n",
        "    #   NO Object Loss #\n",
        "    ####################\n",
        "    # we only apply the loss when there is noobject\n",
        "    no_object_loss = self.bce(\n",
        "            (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj]),\n",
        "        )\n",
        "\n",
        "    ####################\n",
        "    #    Object Loss   #\n",
        "    ####################\n",
        "    #we only apply this loss for the cells and anchor boxes that has an object\n",
        "    # we reshape to match the dimentins of the height and width \n",
        "    # because we want to be able to muliply and broadcast \"from th fprmula p_w* exp(t_w)\"\n",
        "    anchors = anchors.reshape(1, 3, 1, 1, 2) \n",
        "    # we use sigmoid for the x,y coordinates to mzke them in the range [0,1]\n",
        "    #we use torch.exp for the height and width, and multiply them with anchors\n",
        "    # and concatunate the prevous two over the -1 dimention.\n",
        "    box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n",
        "    ious= intersection_over_union(box_preds[obj], target[...,1:5][obj]).detach()\n",
        "    #only boxes and anchores that has an object\n",
        "    object_loss = self.bce((predictions[..., 0:1][obj]), (ious * target[..., 0:1][obj]))\n",
        "\n",
        "    #########################\n",
        "    # box coordinate Loss   #\n",
        "    #########################\n",
        "\n",
        "    #to make x and y in the range [0,1]\n",
        "    predictions[..., 1:3] = self.sigmoid(predictions[..., 1:3]) \n",
        "    #changing the width and height to the same format as the predictions.\n",
        "    target[..., 3:5] = torch.log((0.0000001 + target[..., 3:5] / anchors))#this is hte inverse function of torch.exp(predictions[..., 3:5]) * anchors]\n",
        "    # we also added a small value to make sure that the derivative doesn't have 1/0'\n",
        "\n",
        "    # compute mse loss for boxes that has an object only\n",
        "    box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n",
        "\n",
        "    ####################\n",
        "    #    Class Loss    #\n",
        "    ####################\n",
        "    #finally predict the classes for the places that has objects using the cross entropy loss\n",
        "    class_loss = self.entropy(\n",
        "            (predictions[..., 5:][obj]), (target[..., 5][obj].long()),\n",
        "        )\n",
        "        \n",
        "    loss= (\n",
        "            self.lambda_box * box_loss\n",
        "            + self.lambda_obj * object_loss\n",
        "            + self.lambda_noobj * no_object_loss\n",
        "            + self.lambda_class * class_loss\n",
        "        )\n",
        "    return loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kakOammoWdJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}